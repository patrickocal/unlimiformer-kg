\subsection*{Alternatives to REBEL}
Other means of performing NER and RE we considered include spaCy-LLM, DyGIE++, and LlamaIndex. spaCy-LLM\footnote{https://spacy.io/usage/large-language-models} is a package that integrates LLMs into natural language processing (NLP) pipelines provided by spaCy, an industry-standard NLP library. In particular, its built-in \texttt{spacy.REL.v1}\footnote{https://github.com/explosion/spacy-llm/tree/main/usage\_examples/rel\_openai} component supports RE with both zero-shot and few-shot prompting, but relies on an upstream NER component for entity extraction. 

DyGIE++ is an RE component that refines and scores text spans designed to capture both intra-sentence and cross-sentence context. We cloned the code from the official GitHub repository linked here\footnote{https://github.com/dwadden/dygiepp} and attempted to replicate the process of training a model for RE, but were unsuccessful due to technical difficulties. 

Finally, LlamaIndex, a framework for connecting data sources for LLMs, has a class called \texttt{KnowledgeGraphIndex}\footnote{https://docs.llamaindex.ai/en/stable/examples/index\_structs/knowledge\_graph/KnowledgeGraphDemo.html} which is compatible with FAISS, the datastore that \texttt{unlimiformer} uses to conduct $k$-NN searches of top-level hidden state encodings, which would simplify our task of NER and RE.