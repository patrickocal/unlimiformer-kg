\subsection*{To-Do List (Remove When Done)}
1. Explain objective function we are optimizing during training.

2. Submit test results to Scrolls.

3. Email Tolu on how to present code that doesn't run on Colab.

4. Present key result that length of summary is strongly dependent on input: LD < KG + LD < KG. Explain why this is.

5. Upload models to Hugging Face.

6. Figures

6.1 Shakespeare image with KG / dramatis personae.

6.2 The Mirror and the Light (Hilary Mantel).

6.3 Sheel's KG.

6.4 Plot distribution of LD, KG, and summary sizes for the 3 splits.

6.5 Graph convergence of summary length (number of tokens) to 90 for LDs, 750 for combined, 800+ for KGs.

6.6 Training / loss and other graphs from the training.

6.7 Table of results comparing R1, R2, RL, BERTScore F1 for the 3 experiments. Bold the best performers.